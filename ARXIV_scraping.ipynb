{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ARXIV_scraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scraping Arxiv using the arXiv API\n",
        "From https://arxiv.org/help/api/user-manual#detailed_examples"
      ],
      "metadata": {
        "id": "Lb0qUQzSugHs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGnZjrFvubpR",
        "outputId": "7da9818e-9088-4a68-e4d4-d5c8104cd4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3Dall%3Aelectron%26id_list%3D%26start%3D0%26max_results%3D1\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=all:electron&amp;id_list=&amp;start=0&amp;max_results=1</title>\\n  <id>http://arxiv.org/api/cHxbiOdZaP56ODnBPIenZhzg5f8</id>\\n  <updated>2022-02-19T00:00:00-05:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">180619</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:itemsPerPage>\\n  <entry>\\n    <id>http://arxiv.org/abs/cond-mat/0102536v1</id>\\n    <updated>2001-02-28T20:12:09Z</updated>\\n    <published>2001-02-28T20:12:09Z</published>\\n    <title>Impact of Electron-Electron Cusp on Configuration Interaction Energies</title>\\n    <summary>  The effect of the electron-electron cusp on the convergence of configuration\\ninteraction (CI) wave functions is examined. By analogy with the\\npseudopotential approach for electron-ion interactions, an effective\\nelectron-electron interaction is developed which closely reproduces the\\nscattering of the Coulomb interaction but is smooth and finite at zero\\nelectron-electron separation. The exact many-electron wave function for this\\nsmooth effective interaction has no cusp at zero electron-electron separation.\\nWe perform CI and quantum Monte Carlo calculations for He and Be atoms, both\\nwith the Coulomb electron-electron interaction and with the smooth effective\\nelectron-electron interaction. We find that convergence of the CI expansion of\\nthe wave function for the smooth electron-electron interaction is not\\nsignificantly improved compared with that for the divergent Coulomb interaction\\nfor energy differences on the order of 1 mHartree. This shows that, contrary to\\npopular belief, description of the electron-electron cusp is not a limiting\\nfactor, to within chemical accuracy, for CI calculations.\\n</summary>\\n    <author>\\n      <name>David Prendergast</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Department of Physics</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>M. Nolan</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NMRC, University College, Cork, Ireland</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Claudia Filippi</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Department of Physics</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>Stephen Fahy</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Department of Physics</arxiv:affiliation>\\n    </author>\\n    <author>\\n      <name>J. C. Greer</name>\\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">NMRC, University College, Cork, Ireland</arxiv:affiliation>\\n    </author>\\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1063/1.1383585</arxiv:doi>\\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1063/1.1383585\" rel=\"related\"/>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">11 pages, 6 figures, 3 tables, LaTeX209, submitted to The Journal of\\n  Chemical Physics</arxiv:comment>\\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">J. Chem. Phys. 115, 1626 (2001)</arxiv:journal_ref>\\n    <link href=\"http://arxiv.org/abs/cond-mat/0102536v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cond-mat/0102536v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cond-mat.str-el\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cond-mat.str-el\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n</feed>\\n'\n"
          ]
        }
      ],
      "source": [
        "# python example\n",
        "import urllib.request as libreq\n",
        "with libreq.urlopen('http://export.arxiv.org/api/query?search_query=all:electron&start=0&max_results=1') as url:\n",
        "  r = url.read()\n",
        "print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# arXiv API search using article ID\n",
        "Summary query:\n",
        "```\n",
        "import urllib.request as libreq\n",
        "with libreq.urlopen('http://export.arxiv.org/api/query?id_list=2108.13624') as url:\n",
        "  r = url.read()\n",
        "print(r)\n",
        "```"
      ],
      "metadata": {
        "id": "RrnQNuWT3rAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as libreq\n",
        "with libreq.urlopen('http://export.arxiv.org/api/query?id_list=2108.13624') as url:\n",
        "  r = url.read()\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu7mxPFh3muJ",
        "outputId": "c0f10a41-7c9a-4a11-ce74-9e00296f89e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3D%26id_list%3D2108.13624%26start%3D0%26max_results%3D10\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=&amp;id_list=2108.13624&amp;start=0&amp;max_results=10</title>\\n  <id>http://arxiv.org/api/Mh2DkleZEdxgGlPyXhg/tpeZS/c</id>\\n  <updated>2022-02-19T00:00:00-05:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">10</opensearch:itemsPerPage>\\n  <entry>\\n    <id>http://arxiv.org/abs/2108.13624v1</id>\\n    <updated>2021-08-31T05:28:42Z</updated>\\n    <published>2021-08-31T05:28:42Z</published>\\n    <title>Towards Out-Of-Distribution Generalization: A Survey</title>\\n    <summary>  Classic machine learning methods are built on the $i.i.d.$ assumption that\\ntraining and testing data are independent and identically distributed. However,\\nin real scenarios, the $i.i.d.$ assumption can hardly be satisfied, rendering\\nthe sharp drop of classic machine learning algorithms\\' performances under\\ndistributional shifts, which indicates the significance of investigating the\\nOut-of-Distribution generalization problem. Out-of-Distribution (OOD)\\ngeneralization problem addresses the challenging setting where the testing\\ndistribution is unknown and different from the training. This paper serves as\\nthe first effort to systematically and comprehensively discuss the OOD\\ngeneralization problem, from the definition, methodology, evaluation to the\\nimplications and future directions. Firstly, we provide the formal definition\\nof the OOD generalization problem. Secondly, existing methods are categorized\\ninto three parts based on their positions in the whole learning pipeline,\\nnamely unsupervised representation learning, supervised model learning and\\noptimization, and typical methods for each category are discussed in detail. We\\nthen demonstrate the theoretical connections of different categories, and\\nintroduce the commonly used datasets and evaluation metrics. Finally, we\\nsummarize the whole literature and raise some future directions for OOD\\ngeneralization problem. The summary of OOD generalization methods reviewed in\\nthis survey can be found at http://out-of-distribution-generalization.com.\\n</summary>\\n    <author>\\n      <name>Zheyan Shen</name>\\n    </author>\\n    <author>\\n      <name>Jiashuo Liu</name>\\n    </author>\\n    <author>\\n      <name>Yue He</name>\\n    </author>\\n    <author>\\n      <name>Xingxuan Zhang</name>\\n    </author>\\n    <author>\\n      <name>Renzhe Xu</name>\\n    </author>\\n    <author>\\n      <name>Han Yu</name>\\n    </author>\\n    <author>\\n      <name>Peng Cui</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2108.13624v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2108.13624v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n</feed>\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output\n",
        "\n",
        "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3D%26id_list%3D2108.13624%26start%3D0%26max_results%3D10\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=&amp;id_list=2108.13624&amp;start=0&amp;max_results=10</title>\\n  <id>http://arxiv.org/api/Mh2DkleZEdxgGlPyXhg/tpeZS/c</id>\\n  <updated>2022-02-19T00:00:00-05:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">10</opensearch:itemsPerPage>\\n  <entry>\\n    <id>http://arxiv.org/abs/2108.13624v1</id>\\n    <updated>2021-08-31T05:28:42Z</updated>\\n    <published>2021-08-31T05:28:42Z</published>\\n    <title>Towards Out-Of-Distribution Generalization: A Survey</title>\\n    <summary>  Classic machine learning methods are built on the $i.i.d.$ assumption that\\ntraining and testing data are independent and identically distributed. However,\\nin real scenarios, the $i.i.d.$ assumption can hardly be satisfied, rendering\\nthe sharp drop of classic machine learning algorithms\\' performances under\\ndistributional shifts, which indicates the significance of investigating the\\nOut-of-Distribution generalization problem. Out-of-Distribution (OOD)\\ngeneralization problem addresses the challenging setting where the testing\\ndistribution is unknown and different from the training. This paper serves as\\nthe first effort to systematically and comprehensively discuss the OOD\\ngeneralization problem, from the definition, methodology, evaluation to the\\nimplications and future directions. Firstly, we provide the formal definition\\nof the OOD generalization problem. Secondly, existing methods are categorized\\ninto three parts based on their positions in the whole learning pipeline,\\nnamely unsupervised representation learning, supervised model learning and\\noptimization, and typical methods for each category are discussed in detail. We\\nthen demonstrate the theoretical connections of different categories, and\\nintroduce the commonly used datasets and evaluation metrics. Finally, we\\nsummarize the whole literature and raise some future directions for OOD\\ngeneralization problem. The summary of OOD generalization methods reviewed in\\nthis survey can be found at http://out-of-distribution-generalization.com.\\n</summary>\\n    <author>\\n      <name>Zheyan Shen</name>\\n    </author>\\n    <author>\\n      <name>Jiashuo Liu</name>\\n    </author>\\n    <author>\\n      <name>Yue He</name>\\n    </author>\\n    <author>\\n      <name>Xingxuan Zhang</name>\\n    </author>\\n    <author>\\n      <name>Renzhe Xu</name>\\n    </author>\\n    <author>\\n      <name>Han Yu</name>\\n    </author>\\n    <author>\\n      <name>Peng Cui</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2108.13624v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2108.13624v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n</feed>\\n'\n"
      ],
      "metadata": {
        "id": "I9ndeoIt7sHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# arXiv all query\n",
        "```\n",
        "import urllib.request as libreq\n",
        "with libreq.urlopen('http://export.arxiv.org/api/query?all=2108.13624') as url:\n",
        "  r = url.read()\n",
        "print(r)\n",
        "```"
      ],
      "metadata": {
        "id": "Nj4IFxrW4whc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as libreq\n",
        "with libreq.urlopen('http://export.arxiv.org/api/query?all=2108.13624') as url:\n",
        "  r = url.read()\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhXxRpCz481F",
        "outputId": "28983b72-2bb3-47a2-b39e-8055410ffce9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3D%26id_list%3D%26start%3D0%26max_results%3D10\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=&amp;id_list=&amp;start=0&amp;max_results=10</title>\\n  <id>http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM</id>\\n  <updated>2022-02-19T00:00:00-05:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">10</opensearch:itemsPerPage>\\n</feed>\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request as libreq\n",
        "with libreq.urlopen('http://export.arxiv.org/api/query?all=2108.13624') as url:\n",
        "  r = url.read()\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ulJ_QeN5Tt1",
        "outputId": "aeb7166f-b380-4738-f103-b06c485e01e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3D%26id_list%3D%26start%3D0%26max_results%3D10\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=&amp;id_list=&amp;start=0&amp;max_results=10</title>\\n  <id>http://arxiv.org/api/iQlyOhQ3W8t8kI903+StmrBZNWM</id>\\n  <updated>2022-02-19T00:00:00-05:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">10</opensearch:itemsPerPage>\\n</feed>\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example from:\n",
        "```\n",
        "https://arxiv.org/help/api/user-manual#detailed_examples\n",
        "https://static.arxiv.org/static/arxiv.marxdown/0.1/help/api/examples/python_arXiv_parsing_example.txt\n",
        "```"
      ],
      "metadata": {
        "id": "YzQtyz7j8rTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "python_arXiv_parsing_example.py\n",
        "\n",
        "This sample script illustrates a basic arXiv api call\n",
        "followed by parsing of the results using the \n",
        "feedparser python module.\n",
        "\n",
        "Please see the documentation at \n",
        "http://export.arxiv.org/api_help/docs/user-manual.html\n",
        "for more information, or email the arXiv api \n",
        "mailing list at arxiv-api@googlegroups.com.\n",
        "\n",
        "urllib is included in the standard python library.\n",
        "feedparser can be downloaded from http://feedparser.org/ .\n",
        "\n",
        "Author: Julius B. Lucks\n",
        "\n",
        "This is free software.  Feel free to do what you want\n",
        "with it, but please play nice with the arXiv API!\n",
        "\"\"\"\n",
        "\n",
        "import urllib\n",
        "import urllib.request\n",
        "# feedparser issues\n",
        "# https://github.com/sabnzbd/sabnzbd/issues/1567\n",
        "# https://stackoverflow.com/questions/6445167/force-python-to-use-an-older-version-of-module-than-what-i-have-installed-now\n",
        "\n",
        "import pkg_resources\n",
        "# pkg_resources.require(\"feedparser==5.2.1\") # Raises error, then ran\n",
        "# https://stackoverflow.com/questions/46829474/attributeerror-module-feedparser-has-no-attribute-feedparserdict\n",
        "# import feedparser\n",
        "# print(feedparser.__version__)\n",
        "# print(feedparser.FeedParserDict)\n",
        "# 6.0.8\n",
        "# <class 'feedparser.util.FeedParserDict'>\n",
        "\n",
        "# pkg_resources.require(\"feedparser==6.0.8\")\n",
        "pkg_resources.require(\"feedparser==5.2.1\") # after restarting runtime\n",
        "# error \n",
        "# VersionConflict: (feedparser 5.2.1 (/usr/local/lib/python3.7/dist-packages), Requirement.parse('feedparser==6.0.8'))\n",
        "# !pip install \n",
        "\n",
        "import feedparser\n",
        "# !pip install feedparser==6.0.8 # + runtime restart\n",
        "\n",
        "# Base api query url\n",
        "base_url = 'http://export.arxiv.org/api/query?';\n",
        "\n",
        "# Search parameters\n",
        "# search_query = 'all:electron' # search for electron in all fields\n",
        "search_query = 'id_list=2108.13624'\n",
        "start = 0                     # retreive the first 5 results\n",
        "max_results = 5\n",
        "\n",
        "# query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
        " #                                                    start,\n",
        " #                                                    max_results)\n",
        "query = '%s' % (search_query)\n",
        "print(query)\n",
        "exit\n",
        "\n",
        "# Opensearch metadata such as totalResults, startIndex, \n",
        "# and itemsPerPage live in the opensearch namespase.\n",
        "# Some entry metadata lives in the arXiv namespace.\n",
        "# This is a hack to expose both of these namespaces in\n",
        "# feedparser v4.1\n",
        "#feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
        "#feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
        "feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
        "feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
        "\n",
        "# perform a GET request using the base_url and query\n",
        "# https://stackoverflow.com/questions/39975367/attributeerror-module-urllib-has-no-attribute-urlopen/39975383\n",
        "# AttributeError: module 'urllib' has no attribute 'urlopen'\n",
        "# response = urllib.urlopen(base_url+query).read()\n",
        "response = urllib.request.urlopen(base_url+query).read()\n",
        "\n",
        "\n",
        "# parse the response using feedparser\n",
        "feed = feedparser.parse(response)\n",
        "\n",
        "# print out feed information\n",
        "print('Feed title: %s' % feed.feed.title)\n",
        "print('Feed last updated: %s' % feed.feed.updated)\n",
        "\n",
        "# print opensearch metadata\n",
        "print('totalResults for this query: %s' % feed.feed.opensearch_totalresults)\n",
        "print('itemsPerPage for this query: %s' % feed.feed.opensearch_itemsperpage)\n",
        "print('startIndex for this query: %s'   % feed.feed.opensearch_startindex)\n",
        "\n",
        "# Run through each entry, and print out information\n",
        "for entry in feed.entries:\n",
        "    print('e-print metadata')\n",
        "    print('arxiv-id: %s' % entry.id.split('/abs/')[-1])\n",
        "    print('Published: %s' % entry.published)\n",
        "    print('Title:  %s' % entry.title)\n",
        "    \n",
        "    # feedparser v4.1 only grabs the first author\n",
        "    author_string = entry.author\n",
        "    \n",
        "    # grab the affiliation in <arxiv:affiliation> if present\n",
        "    # - this will only grab the first affiliation encountered\n",
        "    #   (the first affiliation for the first author)\n",
        "    # Please email the list with a way to get all of this information!\n",
        "    try:\n",
        "        author_string += ' (%s)' % entry.arxiv_affiliation\n",
        "    except AttributeError:\n",
        "        pass\n",
        "    \n",
        "    print('Last Author:  %s' % author_string)\n",
        "    \n",
        "    # feedparser v5.0.1 correctly handles multiple authors, print them all\n",
        "    try:\n",
        "        print('Authors:  %s' % ', '.join(author.name for author in entry.authors))\n",
        "    except AttributeError:\n",
        "        pass\n",
        "\n",
        "    # get the links to the abs page and pdf for this e-print\n",
        "    for link in entry.links:\n",
        "        if link.rel == 'alternate':\n",
        "            print('abs page link: %s' % link.href)\n",
        "        elif link.title == 'pdf':\n",
        "            print('pdf link: %s' % link.href)\n",
        "    \n",
        "    # The journal reference, comments and primary_category sections live under \n",
        "    # the arxiv namespace\n",
        "    try:\n",
        "        journal_ref = entry.arxiv_journal_ref\n",
        "    except AttributeError:\n",
        "        journal_ref = 'No journal ref found'\n",
        "    print('Journal reference: %s' % journal_ref)\n",
        "    \n",
        "    try:\n",
        "        comment = entry.arxiv_comment\n",
        "    except AttributeError:\n",
        "        comment = 'No comment found'\n",
        "    print('Comments: %s' % comment)\n",
        "    \n",
        "    # Since the <arxiv:primary_category> element has no data, only\n",
        "    # attributes, feedparser does not store anything inside\n",
        "    # entry.arxiv_primary_category\n",
        "    # This is a dirty hack to get the primary_category, just take the\n",
        "    # first element in entry.tags.  If anyone knows a better way to do\n",
        "    # this, please email the list!\n",
        "    print('Primary Category: %s' % entry.tags[0]['term'])\n",
        "    \n",
        "    # Lets get all the categories\n",
        "    all_categories = [t['term'] for t in entry.tags]\n",
        "    print('All Categories: %s' % (', ').join(all_categories))\n",
        "    \n",
        "    # The abstract is in the <summary> element\n",
        "\n",
        "    print('Abstract: %s' %  entry.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ew2B1f38tSC",
        "outputId": "76c95149-0b01-4efe-af68-76b2bd8b0db1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id_list=2108.13624\n",
            "Feed title: ArXiv Query: search_query=&amp;id_list=2108.13624&amp;start=0&amp;max_results=10\n",
            "Feed last updated: 2022-02-19T00:00:00-05:00\n",
            "totalResults for this query: 1\n",
            "itemsPerPage for this query: 10\n",
            "startIndex for this query: 0\n",
            "e-print metadata\n",
            "arxiv-id: 2108.13624v1\n",
            "Published: 2021-08-31T05:28:42Z\n",
            "Title:  Towards Out-Of-Distribution Generalization: A Survey\n",
            "Last Author:  Peng Cui\n",
            "Authors:  Zheyan Shen, Jiashuo Liu, Yue He, Xingxuan Zhang, Renzhe Xu, Han Yu, Peng Cui\n",
            "abs page link: http://arxiv.org/abs/2108.13624v1\n",
            "pdf link: http://arxiv.org/pdf/2108.13624v1\n",
            "Journal reference: No journal ref found\n",
            "Comments: No comment found\n",
            "Primary Category: cs.LG\n",
            "All Categories: cs.LG\n",
            "Abstract: Classic machine learning methods are built on the $i.i.d.$ assumption that\n",
            "training and testing data are independent and identically distributed. However,\n",
            "in real scenarios, the $i.i.d.$ assumption can hardly be satisfied, rendering\n",
            "the sharp drop of classic machine learning algorithms' performances under\n",
            "distributional shifts, which indicates the significance of investigating the\n",
            "Out-of-Distribution generalization problem. Out-of-Distribution (OOD)\n",
            "generalization problem addresses the challenging setting where the testing\n",
            "distribution is unknown and different from the training. This paper serves as\n",
            "the first effort to systematically and comprehensively discuss the OOD\n",
            "generalization problem, from the definition, methodology, evaluation to the\n",
            "implications and future directions. Firstly, we provide the formal definition\n",
            "of the OOD generalization problem. Secondly, existing methods are categorized\n",
            "into three parts based on their positions in the whole learning pipeline,\n",
            "namely unsupervised representation learning, supervised model learning and\n",
            "optimization, and typical methods for each category are discussed in detail. We\n",
            "then demonstrate the theoretical connections of different categories, and\n",
            "introduce the commonly used datasets and evaluation metrics. Finally, we\n",
            "summarize the whole literature and raise some future directions for OOD\n",
            "generalization problem. The summary of OOD generalization methods reviewed in\n",
            "this survey can be found at http://out-of-distribution-generalization.com.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference scraping\n",
        "Continuing from https://github.com/dsikar/semanticscholar"
      ],
      "metadata": {
        "id": "lw95o_ebP-CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adapting getAllInfo to return references\n",
        "def getAllInfo(suffix, start, end) :\n",
        "    \"\"\"\n",
        "    Get AI2/DOI Semantic Scholar complete article info\n",
        "    Inputs\n",
        "        suffix: string, DOI suffix\n",
        "        start: integer, first paper index\n",
        "        end: integer, last paper index\n",
        "    Examples:\n",
        "    Output\n",
        "        papers: list of dictionaries\n",
        "        \n",
        "    # SAFECOMP 2020 get all 31 papers\n",
        "    text = getInfo('10.1007/978-3-030-55583-2_', 1, 31, 'abstract')  \n",
        "    all keys:\n",
        "    'abstract', 'arxivId', 'authors', 'citationVelocity', 'citations', 'corpusId', 'doi', 'fieldsOfStudy', \n",
        "    'influentialCitationCount', 'isOpenAccess', 'isPublisherLicensed', 'is_open_access', 'is_publisher_licensed', \n",
        "    'numCitedBy', 'numCiting', 'paperId', 'references', 'title', 'topics', 'url', 'venue', 'year'\n",
        "    \"\"\"\n",
        "    import time\n",
        "    import semanticscholar as sch \n",
        "    papers = []\n",
        "    for i in range (start,end+1) :\n",
        "        doi = suffix + str(i)\n",
        "        paper = sch.paper(doi, timeout=2)\n",
        "        if 'abstract' in paper :\n",
        "            print('Found paper DOI:', doi)\n",
        "            papers.append(paper)\n",
        "        else :\n",
        "            print('No abstract for paper index {}'.format(i))\n",
        "            print(\"DOI entry: \", doi)\n",
        "        time.sleep(3)\n",
        "    return papers\n",
        "\n",
        " # key 244958432"
      ],
      "metadata": {
        "id": "eX3Jyu1GRTEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install semanticscholar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N50M6IeCSHsS",
        "outputId": "21d309a1-a746-46e2-94de-7ac402a7258a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting semanticscholar\n",
            "  Downloading semanticscholar-0.2.1-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.7/dist-packages (from semanticscholar) (8.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from semanticscholar) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->semanticscholar) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->semanticscholar) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->semanticscholar) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->semanticscholar) (1.24.3)\n",
            "Installing collected packages: semanticscholar\n",
            "Successfully installed semanticscholar-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# key 244958432\n",
        "import semanticscholar as sch \n",
        "mydoi = '244958432'\n",
        "doi = mydoi\n",
        "paper = sch.paper(doi, timeout=2)\n",
        "# no results"
      ],
      "metadata": {
        "id": "11t51yMFSNFT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(type(paper)) # <class 'dict'>\n",
        "for keys in paper:\n",
        "  print(keys)"
      ],
      "metadata": {
        "id": "_4riM9HbSlB1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stopped here\n",
        "# this URL returns metadata in JSON format\n",
        "# https://api.semanticscholar.org/v1/paper/CorpusID:244958432"
      ],
      "metadata": {
        "id": "F7fvoa3-Tmu3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}